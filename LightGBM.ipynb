{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LightGBM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stasSajin/colab_notebooks/blob/master/LightGBM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsYA23-ySjCa",
        "colab_type": "text"
      },
      "source": [
        "# Visualize LightGBM performance in one line of code\n",
        "Gradient boosting decision trees are the state of the art when it comes to building predictive models for structured data.\n",
        "\n",
        "[LigthGBM](https://github.com/microsoft/LightGBM), a gradient boosting framework by Microsoft, has recently dethroned xgboost and become the go to GBDT algorithm (along with catboost). It outperforms xgboost in training speeds, memory usage and the size of datasets it can handle. LightGBM does so by using histogram-based algorithms to bucket continuous features into discrete bins during training.\n",
        "\n",
        "We want to make it incredible easy for people to look under the hood of their models, so we built a callback that helps you visualize your LightGBMâ€™s performance in just one line of code.\n",
        "\n",
        "<img src=\"https://paper-attachments.dropbox.com/s_64984776E9C3600B2F541866A33ED2467F8DEC17543DF8244C2E643993740430_1578873986950_image.png\" alt=\"lightgbm_performance\" style=\"width: 50%\"/>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Edb6-rGb3KlL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install wandb -qq"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wF-3RxY2EdOU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://raw.githubusercontent.com/microsoft/LightGBM/master/examples/regression/regression.train -qq\n",
        "!wget https://raw.githubusercontent.com/microsoft/LightGBM/master/examples/regression/regression.test -qq"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rb6UKnUtBMBR",
        "colab_type": "code",
        "outputId": "a68ab3d9-80da-455b-bd4d-85dcd8dacb10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# import wandb and the lightgbm callback\n",
        "import wandb\n",
        "from wandb.lightgbm import wandb_callback\n",
        "import lightgbm as lgb\n",
        "import pandas as pd\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# initialize a new wandb project\n",
        "wandb.init(project='lightgbm')\n",
        "\n",
        "# load or create your dataset\n",
        "df_train = pd.read_csv('regression.train', header=None, sep='\\t')\n",
        "df_test = pd.read_csv('regression.test', header=None, sep='\\t')\n",
        "\n",
        "y_train = df_train[0]\n",
        "y_test = df_test[0]\n",
        "X_train = df_train.drop(0, axis=1)\n",
        "X_test = df_test.drop(0, axis=1)\n",
        "\n",
        "# create dataset for lightgbm\n",
        "lgb_train = lgb.Dataset(X_train, y_train)\n",
        "lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)\n",
        "\n",
        "# specify your configurations as a dict\n",
        "params = {\n",
        "    'boosting_type': 'gbdt',\n",
        "    'objective': 'regression',\n",
        "    'metric': {'rmse', 'l2', 'l1', 'huber'},\n",
        "    'num_leaves': 31,\n",
        "    'learning_rate': 0.05,\n",
        "    'feature_fraction': 0.9,\n",
        "    'bagging_fraction': 0.8,\n",
        "    'bagging_freq': 5,\n",
        "    'verbosity': -1\n",
        "}\n",
        "# wandb.config.update(params)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/lavanyashukla/lightgbm\" target=\"_blank\">https://app.wandb.ai/lavanyashukla/lightgbm</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/lavanyashukla/lightgbm/runs/988256ze\" target=\"_blank\">https://app.wandb.ai/lavanyashukla/lightgbm/runs/988256ze</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmBJfKH0Fzwn",
        "colab_type": "code",
        "outputId": "59fb3ae5-e8b7-442d-d224-51bf1878f3b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 869
        }
      },
      "source": [
        "%%wandb\n",
        "# train\n",
        "# add lightgbm callback\n",
        "gbm = lgb.train(params,\n",
        "                lgb_train,\n",
        "                num_boost_round=20,\n",
        "                valid_sets=lgb_eval,\n",
        "                valid_names=('validation'),\n",
        "                callbacks=[wandb_callback()],\n",
        "                early_stopping_rounds=5)\n",
        "\n",
        "# predict\n",
        "y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration)\n",
        "# eval\n",
        "print('The rmse of prediction is:', mean_squared_error(y_test, y_pred) ** 0.5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<iframe src=\"https://app.wandb.ai/lavanyashukla/lightgbm/runs/988256ze?jupyter=true&state=paused\" style=\"border:none;width:100%;height:420px\">\n",
              "                </iframe>"
            ],
            "text/plain": [
              "<wandb.jupyter.Run at 0x7f8cc1d2e940>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[1]\tvalidation's l2: 0.243481\tvalidation's l1: 0.492417\tvalidation's huber: 0.121741\tvalidation's rmse: 0.493438\n",
            "Training until validation scores don't improve for 5 rounds.\n",
            "[2]\tvalidation's l2: 0.240045\tvalidation's l1: 0.48874\tvalidation's huber: 0.120023\tvalidation's rmse: 0.489944\n",
            "[3]\tvalidation's l2: 0.236636\tvalidation's l1: 0.485042\tvalidation's huber: 0.118318\tvalidation's rmse: 0.486452\n",
            "[4]\tvalidation's l2: 0.232959\tvalidation's l1: 0.480872\tvalidation's huber: 0.116479\tvalidation's rmse: 0.482658\n",
            "[5]\tvalidation's l2: 0.229684\tvalidation's l1: 0.476928\tvalidation's huber: 0.114842\tvalidation's rmse: 0.479254\n",
            "[6]\tvalidation's l2: 0.226942\tvalidation's l1: 0.473545\tvalidation's huber: 0.113471\tvalidation's rmse: 0.476384\n",
            "[7]\tvalidation's l2: 0.223972\tvalidation's l1: 0.469984\tvalidation's huber: 0.111986\tvalidation's rmse: 0.473256\n",
            "[8]\tvalidation's l2: 0.220928\tvalidation's l1: 0.466083\tvalidation's huber: 0.110464\tvalidation's rmse: 0.47003\n",
            "[9]\tvalidation's l2: 0.217949\tvalidation's l1: 0.462164\tvalidation's huber: 0.108975\tvalidation's rmse: 0.46685\n",
            "[10]\tvalidation's l2: 0.21512\tvalidation's l1: 0.458352\tvalidation's huber: 0.10756\tvalidation's rmse: 0.46381\n",
            "[11]\tvalidation's l2: 0.212605\tvalidation's l1: 0.454792\tvalidation's huber: 0.106302\tvalidation's rmse: 0.461091\n",
            "[12]\tvalidation's l2: 0.210519\tvalidation's l1: 0.451692\tvalidation's huber: 0.105259\tvalidation's rmse: 0.458823\n",
            "[13]\tvalidation's l2: 0.208728\tvalidation's l1: 0.448774\tvalidation's huber: 0.104364\tvalidation's rmse: 0.456867\n",
            "[14]\tvalidation's l2: 0.207585\tvalidation's l1: 0.446628\tvalidation's huber: 0.103792\tvalidation's rmse: 0.455615\n",
            "[15]\tvalidation's l2: 0.206254\tvalidation's l1: 0.44419\tvalidation's huber: 0.103127\tvalidation's rmse: 0.454152\n",
            "[16]\tvalidation's l2: 0.20433\tvalidation's l1: 0.441229\tvalidation's huber: 0.102165\tvalidation's rmse: 0.452029\n",
            "[17]\tvalidation's l2: 0.20294\tvalidation's l1: 0.438937\tvalidation's huber: 0.10147\tvalidation's rmse: 0.450489\n",
            "[18]\tvalidation's l2: 0.201385\tvalidation's l1: 0.436752\tvalidation's huber: 0.100693\tvalidation's rmse: 0.44876\n",
            "[19]\tvalidation's l2: 0.20008\tvalidation's l1: 0.434243\tvalidation's huber: 0.10004\tvalidation's rmse: 0.447303\n",
            "[20]\tvalidation's l2: 0.198988\tvalidation's l1: 0.43204\tvalidation's huber: 0.0994941\tvalidation's rmse: 0.446081\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[20]\tvalidation's l2: 0.198988\tvalidation's l1: 0.43204\tvalidation's huber: 0.0994941\tvalidation's rmse: 0.446081\n",
            "The rmse of prediction is: 0.44608104506090057\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vwz_5bmxvLeq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}